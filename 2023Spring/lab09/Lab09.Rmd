---
title: "Lab09"
output:
  pdf_document: default
  html_document: default
date: "2023-04-03"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
knitr::opts_chunk$set(fig.width = 6)
knitr::opts_chunk$set(fig.height = 4)
library(tidyverse)
```

# Introduction

In this lab, we will use linear regression to predict the red wine quality using physicochemical tests scores such as citric acid, pH, etc.

But first, a review of using the `lm()` and `predict()` functions.

```{r}
x1 = rnorm(100)
x2 = rnorm(100)
y= 2*x1 + x2 + rnorm(100)
lm_out = lm(y~x1 + x2)
summary(lm_out)
```

Calculate prediction for y when x1 is 1 and x2 is 0.5.

```{r}
lm_out$coefficients[1] + lm_out$coefficients[2]* 1 + lm_out$coefficients[3]* 0.5 
```

Another way to do this.

```{r}
predict(lm_out, newdata = data.frame(x1= 1, x2= 0.5))
```

Can do several at once.

```{r}
predict(lm_out, newdata = data.frame(x1= c(1, 2), x2= c(0.5, -1) ))
```

A few other notes on regression. 

1) If you try to predict one variable and include a perfectly correlated variable in the prediction set, then that variable will be perfectly fit to the outcome to the exclusion of all others.

```{r}
perf_cor = y/4
summary(lm( y ~ perf_cor + x1 + x2 ))
```


2) If there are more variables used for prediction than there are observations, `lm` will only keep the first n-1 variables.

```{r}
x3= rnorm(100)
x4= rnorm(100)
x5= rnorm(100)

all_x = data.frame(x1,x2,x3,x4,x5, y) # 100 x 6 df
lm(y~ . ,data= all_x[1:4,]) # only use the first 4 observations (4<5)
# Then lm only use the first 4-1=3 variables
```




## Wine data

The wine dataset is related to red variants of the Portuguese "Vinho Verde" wine. There are 1599 samples available in the dataset. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.). 

The explanatory variables are all continuous variables based on physicochemical tests:

- **fixed acidity**
- **volatile acidity**
- **citric acid**
- **residual sugar**
- **chlorides**
- **free sulfur dioxide**
- **total sulfur dioxide**
- **density**
- **pH**
- **sulphates**
- **alcohol**

The response variable is the **quality** score between 0 and 10 (based on sensory data).

Read data. We randomly split the data into two parts-the `wine` dataset with 1199 samples and the `wine.test` dataset with 400 samples. Splitting the dataset is a common technique when we want to evaluate the model performance. There are training set, validation set, and test set. The validation set is used for model selection. That is, to estimate the performance of the different model in order to choose the best one. The test set is used for estimating the performance of our final model.

```{r}
## Read data
set.seed("2022")
wine.dataset <- read.csv("winequality-red.csv", sep = ";")
test.samples <- sample(1:nrow(wine.dataset), 400)
wine <- wine.dataset[-test.samples, ]
wine.test <- wine.dataset[test.samples, ]
```

To check the correlation between explanatory variables:

```{r}
library(pheatmap)
corr.wine <- cor(wine[, -1])
pheatmap(corr.wine, treeheight_row = 0, treeheight_col = 0, 
         display_numbers = T, fontsize_number = 0.5)
```

We now fit the linear regression using all of the explanatory variables:

```{r}
wine.fit <- lm(quality ~. ,data = na.omit(wine))
summary(wine.fit)
```


# Multiple regression with diamond price data

This is a very large data set showing various factors of over 50,000 diamonds including price, cut, color, clarity, etc. We are interested in diamond price `price` and how different factors influence it.

| Variable   | Description                                           |
| :--------  | :---------------------------------------------------- |
| **price**  | price in US dollars (\$326–\$18,823)                  |
| **carat**  | weight of the diamond (0.2–5.01)                      |
| **cut**    | quality of the cut (Fair, Good, Very Good, Premium, Ideal) |
| **color**  | diamond colour, from J (worst) to D (best)            |
| **clarity**  | how clear the diamond is (I1 (worst), SI1, SI2, VS1, VS2, VVS1, VVS2, IF (best)) |
| **length.in.mm** | length in mm (0–10.74)                          |
| **width.of.mm** | width in mm (0–58.9)                             |
| **depth.in.mm** | depth in mm (0–31.8)                             |
| **depth**  | total depth percentage $ = z / mean(x, y) = 2 * z / (x+ y) (43–79)$ |
| **table**  | width of top of diamond relative to widest point (43–95) |



```{r}
diamonds <- read.csv("diamonds.csv")
head(diamonds)
```


## Multiple regression with continuous variable

### Exercise 1 Fit the model and Calculate the Statistics

(a) Fit a linear model to price with all the continuous variables as explanatory variables. Print the summary of your model. 
```{r}
# Insert you code here, save your model as `fit`

```

(b) Calculate the fitted values.
```{r}
# Insert you code here, save your results as `fitted.value`

```


(c) Using the fitted model, we can write the estimated model formula. How do we interpret this equation? _Hint._ Use `summary()` on the model object.

```{Answer}
# Insert your answer

```


## Excercise 2 

Let's use the wine data for this exercise 

```{r}
head(wine)
```

We now fit the linear regression using all of the explanatory variables:

```{r}
wine.fit <- lm(quality ~. ,data = na.omit(wine))
summary(wine.fit)
```


### Confidence Interval


(a) Calculate the confidence interval for all the coefficients from the regression done above. Which of these factors will positively influence the wine quality?

```{r}
# Insert your code here to calculate the confidence intervals for the regression coefficients.

```

(b) Calculate the confidence intervals for the samples in `wine.test` using the model you just fit. Which confidence interval will you use? Confidence intervals for the average response or the prediction interval?

```{r}
# insert your code here and save your confidence intervals as `wine.confint`
# wine.confint <- 
```

(c) What is the percentage that your interval in (b) covers the true **quality** score in `wine.test`? What if you use the other confidence interval? Which one is consistent with your confidence level?

```{r}
# insert your code here and save your percentage as `pct.covered`
# pct.covered <- 
# pct.covered
# insert your code here and save your percentage calculated 
# using the other confidence interval as `pct.covered.other`
# wine.confint.other <- 
# pct.covered.other <- 
# pct.covered.other
```


### Exercise 3 Bootstrap CI

Scale the columns of the dataset using scale() and then make 95% bootstrap confidence intervals for the coefficients for the predictors. Plot these confidence intervals using the plotCI() function in gplots. Code from professor for making bootstrap CI is included. You can use this or write your own code. Use the wine subset as used above.

```{r}
bootstrapLM <- function(y,x, repetitions, confidence.level=0.95){
    # calculate the observed statistics
  stat.obs <- coef(lm(y~., data=x))
  # calculate the bootstrapped statistics
  bootFun<-function(){
          sampled <- sample(1:length(y), size=length(y),replace = TRUE)
          coef(lm(y[sampled]~.,data=x[sampled,])) #small correction here to make it for a matrix x
  }  
  stat.boot<-replicate(repetitions,bootFun())
  # nm <-deparse(substitute(x))
  # row.names(stat.boot)[2]<-nm
  level<-1-confidence.level
  confidence.interval <- apply(stat.boot,1,quantile,probs=c(level/2,1-level/2))
    return(list(confidence.interval = cbind("lower"=confidence.interval[1,],"estimate"=stat.obs,"upper"=confidence.interval[2,]), bootStats=stat.boot))
}
```

```{r}
# insert your code here


```

